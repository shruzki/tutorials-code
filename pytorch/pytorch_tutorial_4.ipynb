{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pytorch-tutorial-4.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 10. Dataset Transforms"
      ],
      "metadata": {
        "id": "NHS29_PN4jPz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RpwmIO5O2eRy"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class WineDataset(Dataset): # inheriting Dataset\n",
        "\n",
        "  def __init__(self, transform=None):\n",
        "    # data loading\n",
        "    xy = np.loadtxt('/content/wine.csv', delimiter=',', dtype=np.float32, skiprows=1)\n",
        "    self.n_samples = xy.shape[0]\n",
        "\n",
        "    # note that we do not convert to tensor here\n",
        "    self.x = xy[:, 1:]\n",
        "    self.y = xy[:, [0]] # n_samples, 1\n",
        "    \n",
        "    self.transform = transform\n",
        "  \n",
        "  def __getitem__(self, index):\n",
        "    sample = self.x[index], self.y[index]\n",
        "\n",
        "    if self.transform:\n",
        "      sample = self.transform(sample)\n",
        "    \n",
        "    return sample\n",
        "  \n",
        "  def __len__(self):\n",
        "    return self.n_samples"
      ],
      "metadata": {
        "id": "SX5KiYEn5Oon"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ToTensor:\n",
        "  def __call__(self, sample):\n",
        "    inputs, targets = sample\n",
        "    return torch.from_numpy(inputs), torch.from_numpy(targets)"
      ],
      "metadata": {
        "id": "wppfLIlfmv-s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = WineDataset(transform=ToTensor())\n",
        "first_data = dataset[0]\n",
        "features, labels = first_data\n",
        "print(type(features), type(labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vPf0YpnWnTKl",
        "outputId": "f5f65358-0267-4fae-ff03-3c5cf7a6ad84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.Tensor'> <class 'torch.Tensor'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = WineDataset(transform=None)\n",
        "first_data = dataset[0]\n",
        "features, labels = first_data\n",
        "print(type(features), type(labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "akWysM48oMhX",
        "outputId": "ec08703b-49f8-4a12-8c9d-e75f2f9f6575"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MulTransform:\n",
        "  def __init__(self, factor):\n",
        "    self.factor = factor\n",
        "  \n",
        "  def __call__(self, sample):\n",
        "    inputs, targets = sample\n",
        "    inputs *= self.factor\n",
        "    return inputs, targets"
      ],
      "metadata": {
        "id": "p6GZxkxDpI2U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = WineDataset(transform=None)\n",
        "first_data = dataset[0]\n",
        "features, labels = first_data\n",
        "print(type(features), type(labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1NOwivXopqpp",
        "outputId": "552d8eae-5e03-43bb-92ef-d3efd0b9a355"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04Jsj2TwqP5N",
        "outputId": "f7f0ee75-c0db-4403-b865-50bf4e8d7aa8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1.423e+01 1.710e+00 2.430e+00 1.560e+01 1.270e+02 2.800e+00 3.060e+00\n",
            " 2.800e-01 2.290e+00 5.640e+00 1.040e+00 3.920e+00 1.065e+03]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "composed = torchvision.transforms.Compose([ToTensor(), MulTransform(4)])\n",
        "dataset = WineDataset(transform=composed)\n",
        "first_data = dataset[0]\n",
        "features, labels = first_data\n",
        "print(type(features), type(labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "guQEGxIipxlh",
        "outputId": "b339f163-a483-4af4-c132-135130f34c91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.Tensor'> <class 'torch.Tensor'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U6pRHHzHqHZF",
        "outputId": "c0800f6a-f6b9-410f-cda6-a489981c05af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([5.6920e+01, 6.8400e+00, 9.7200e+00, 6.2400e+01, 5.0800e+02, 1.1200e+01,\n",
            "        1.2240e+01, 1.1200e+00, 9.1600e+00, 2.2560e+01, 4.1600e+00, 1.5680e+01,\n",
            "        4.2600e+03])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 11. Softmax and Crossentropy"
      ],
      "metadata": {
        "id": "wsN7M29Pqoo1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def softmax(x):\n",
        "    return np.exp(x) / np.sum(np.exp(x), axis=0)"
      ],
      "metadata": {
        "id": "rEqMzIm7qOq_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.array([2.0, 1.0, 0.1])\n",
        "outputs = softmax(x)\n",
        "print('softmax numpy:', outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "doPK3ZQGsQfu",
        "outputId": "c3802ffc-d80f-4919-b3b4-cddee3bc64df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "softmax numpy: [0.65900114 0.24243297 0.09856589]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([2.0, 1.0, 0.1])\n",
        "outputs = torch.softmax(x, dim=0)\n",
        "print(outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-hJpE9xKsTmK",
        "outputId": "eb365d21-eb8c-4c26-95a9-6e5f4db2b4fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.6590, 0.2424, 0.0986])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# softmax loss is combined with crossentropy loss many times\n",
        "def crossentropy(actual, predicted):\n",
        "    loss = -np.sum(actual * np.log(predicted))\n",
        "    return loss"
      ],
      "metadata": {
        "id": "mNXEdFfvsVLx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.array([0.7, 0.2, 0.1])\n",
        "y = np.array([1, 0, 0])\n",
        "print(crossentropy(y, x))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iGoBoHp5zfiS",
        "outputId": "902c9dce-ed1e-4e98-9361-06026c5e6631"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.35667494393873245\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.array([0.1, 0.3, 0.6])\n",
        "print(crossentropy(y, x))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66ZN_mIQzhNI",
        "outputId": "df8fa04a-fd13-4bf9-9c78-53bd3bca44af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.3025850929940455\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PYTORCH\n",
        "import torch.nn as nn\n",
        "\n",
        "loss = nn.CrossEntropyLoss()\n",
        "\n",
        "Y = torch.tensor([0])\n",
        "# nsamples x nclasses = 1x3\n",
        "Y_pred_good = torch.tensor([[2.0, 1.0, 0.1]])\n",
        "Y_pred_bad = torch.tensor([[0.5, 2.0, 0.3]])"
      ],
      "metadata": {
        "id": "lDjh6VxGzi-G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "l1 = loss(Y_pred_good, Y)\n",
        "l2 = loss(Y_pred_bad, Y)\n",
        "\n",
        "print(l1.item())\n",
        "print(l2.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o1clvOSFznKw",
        "outputId": "2721e4ae-a2cb-4d95-b8c2-befb50192508"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.4170299470424652\n",
            "1.840616226196289\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_, predictions1 = torch.max(Y_pred_good, 1)\n",
        "_, predictions2 = torch.max(Y_pred_bad, 1)\n",
        "print(predictions1)\n",
        "print(predictions2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LZ9JlpI5zonV",
        "outputId": "c2ad4d4c-9e55-4d13-b814-4855311d1f30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0])\n",
            "tensor([1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's implement a simple neural net with a couple hidden layers that has a linear layer at the end, with one output for each class. This can be passed through softmax to get the probabilities.\n",
        "In PyTorch, one must be careful because we use the cross entropy loss. Here, we must not use the softmax layer in the neural net!"
      ],
      "metadata": {
        "id": "qNdvPgL3z4M6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# multiclass problem\n",
        "class NeuralNet2(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, num_classes):\n",
        "    super(NeuralNet2, self).__init__()\n",
        "    self.linear1 = nn.Linear(input_size, hidden_size)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.linear2 = nn.Linear(hidden_size, num_classes)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    out = self.linear1(x)\n",
        "    out = self.relu(out)\n",
        "    out = self.linear2(out)\n",
        "    # no softmax at the end\n",
        "    return out"
      ],
      "metadata": {
        "id": "KcNGmjhrzuQi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = NeuralNet2(input_size=28*28, hidden_size=5, num_classes=3)\n",
        "criterion = nn.CrossEntropyLoss() # (applies softmax)"
      ],
      "metadata": {
        "id": "QGKwKXtk04k8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Incase we want neural net to output yes or no answer (whether or not image is that of a dog), we can just change size of output of linear2 layer to 1. So, we have a linear layer with one output only. We can pass the output of this linear layer through sigmoid. We say yes if the sigmoid output is higher than 0.5. We also change loss function to BCELoss. Binary Cross Entropy Loss. Sigmoid has to be implemented at the end."
      ],
      "metadata": {
        "id": "-uHraHhM1rRh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# multiclass problem\n",
        "class NeuralNet1(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size):\n",
        "    super(NeuralNet1, self).__init__()\n",
        "    self.linear1 = nn.Linear(input_size, hidden_size)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.linear2 = nn.Linear(hidden_size, 1)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    out = self.linear1(x)\n",
        "    out = self.relu(out)\n",
        "    out = self.linear2(out)\n",
        "    # sigmoid at the end\n",
        "    y_pred = torch.sigmoid(out)\n",
        "    return y_pred"
      ],
      "metadata": {
        "id": "mUFJpS0v1ovk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = NeuralNet1(input_size=28*28, hidden_size=5)\n",
        "criterion = nn.BCELoss()"
      ],
      "metadata": {
        "id": "t51iosVz2dPl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 12. Activation Functions"
      ],
      "metadata": {
        "id": "7UUem5b02zxb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch\n",
        "# import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "nKdKFnup2wMT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# option 1 (create nn module)\n",
        "class NeuralNet(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size):\n",
        "    super(NeuralNet, self).__init__()\n",
        "    self.linear1 = nn.Linear(input_size, hidden_size)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.linear2 = nn.Linear(hidden_size, 1)\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = self.linear1(x)\n",
        "    out = self.relu(out)\n",
        "    out = self.linear2(out)\n",
        "    out = self.sigmoid(out)\n",
        "    return out"
      ],
      "metadata": {
        "id": "6ezPky9g51zL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# option 2 (use activation function directly in forward pass)\n",
        "class NeuralNet(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size):\n",
        "    super(NeuralNet, self).__init__()\n",
        "    self.linear1 = nn.Linear(input_size, hidden_size)\n",
        "    # self.relu = nn.ReLU()\n",
        "    self.linear2 = nn.Linear(hidden_size, 1)\n",
        "    # self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "  def forward(self, x):\n",
        "    # out = self.linear1(x)\n",
        "    # out = self.relu(out)\n",
        "    # out = self.linear2(out)\n",
        "    # out = self.sigmoid(out)\n",
        "    out = torch.relu(self.linear1(x))\n",
        "    out = torch.sigmoid(self.linear2(out))\n",
        "    return out"
      ],
      "metadata": {
        "id": "S5EfzvwN6mKl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}